This repository contains my implementation of a BERT model for the Stanford CS224n Final Project. 

I only did the first part( without extensions ). Which includes the multi-head self attention, layernorm, embeddings, adamW optimizer etc.

It also contains the jupyter notebook used during training and a train loss/ dev loss curve picture.

Acknowledgement
This project is based on the skeleton code provided by the Stanford CS224n course team (Timothy Dai et al.). The core model implementation (BERT layers, Attention, Optimizer) and experiments are my own work.
